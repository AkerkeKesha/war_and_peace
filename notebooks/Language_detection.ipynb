{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect language "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/Language Detection.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "English       1385\n",
       "French        1014\n",
       "Spanish        819\n",
       "Portugeese     739\n",
       "Italian        698\n",
       "Russian        692\n",
       "Sweedish       676\n",
       "Malayalam      594\n",
       "Dutch          546\n",
       "Arabic         536\n",
       "Turkish        474\n",
       "German         470\n",
       "Tamil          469\n",
       "Danish         428\n",
       "Kannada        369\n",
       "Greek          365\n",
       "Hindi           63\n",
       "Name: Language, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' Nature, in the broadest sense, is the natural, physical, material world or universe.'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.iloc[0].Text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'English'\n",
    "data = data[data.Language.isin(['French', 'Russian'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1706, 2)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "French     1014\n",
       "Russian     692\n",
       "Name: Language, dtype: int64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.Language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def length(text):\n",
    "    words = text.split()\n",
    "    return len(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_ru(col):\n",
    "    return 1 if col == \"Russian\" else 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(text):\n",
    "    # remove numbers in text\n",
    "    text = re.sub(r'[!@#$(),\\n\"%^*?\\:;~`0-9]', ' ', text)\n",
    "    # remove other symbols in text\n",
    "    text = re.sub(r'[[]]', ' ', text)\n",
    "    text = text.lower()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/akerke/Desktop/Masterstudium/4.Semester/MasterThesis/war_and_peace/.venv/lib/python3.7/site-packages/ipykernel_launcher.py:5: FutureWarning: Possible nested set at position 1\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "data['clean'] = data['Text'].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['lang_code'] = data['Language'].apply(is_ru)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['len'] = data['Text'].apply(length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Language</th>\n",
       "      <th>clean</th>\n",
       "      <th>lang_code</th>\n",
       "      <th>len</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3250</th>\n",
       "      <td>Si vous disposez d'ouvrages ou d'articles de r...</td>\n",
       "      <td>French</td>\n",
       "      <td>si vous disposez d'ouvrages ou d'articles de r...</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3251</th>\n",
       "      <td>Comment ajouter mes sources ?</td>\n",
       "      <td>French</td>\n",
       "      <td>comment ajouter mes sources</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3252</th>\n",
       "      <td>Cette page ou section est en train d'être trad...</td>\n",
       "      <td>French</td>\n",
       "      <td>cette page ou section est en train d'être trad...</td>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3253</th>\n",
       "      <td>Vous pouvez aider au développement de Wikipédi...</td>\n",
       "      <td>French</td>\n",
       "      <td>vous pouvez aider au développement de wikipédi...</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3254</th>\n",
       "      <td>Le mot nature est un terme polysémique (c’est-...</td>\n",
       "      <td>French</td>\n",
       "      <td>le mot nature est un terme polysémique  c’est-...</td>\n",
       "      <td>0</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text Language  \\\n",
       "3250  Si vous disposez d'ouvrages ou d'articles de r...   French   \n",
       "3251                      Comment ajouter mes sources ?   French   \n",
       "3252  Cette page ou section est en train d'être trad...   French   \n",
       "3253  Vous pouvez aider au développement de Wikipédi...   French   \n",
       "3254  Le mot nature est un terme polysémique (c’est-...   French   \n",
       "\n",
       "                                                  clean  lang_code  len  \n",
       "3250  si vous disposez d'ouvrages ou d'articles de r...          0   54  \n",
       "3251                      comment ajouter mes sources            0    5  \n",
       "3252  cette page ou section est en train d'être trad...          0   40  \n",
       "3253  vous pouvez aider au développement de wikipédi...          0   16  \n",
       "3254  le mot nature est un terme polysémique  c’est-...          0   50  "
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = cv.fit_transform(data[\"clean\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = data[\"lang_code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "clf = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf.fit(Xtrain, Ytrain)\n",
    "Ypred = clf.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9941520467836257\n"
     ]
    }
   ],
   "source": [
    "accr = accuracy_score(Ytest, Ypred)\n",
    "print(accr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00       215\n",
      "           1       0.99      0.99      0.99       127\n",
      "\n",
      "    accuracy                           0.99       342\n",
      "   macro avg       0.99      0.99      0.99       342\n",
      "weighted avg       0.99      0.99      0.99       342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(Ytest, Ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "languages = {0:\"french\", 1:\"russian\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99777482 0.00222518]]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "x = cv.transform([\"Eh bien, mon prince\"])\n",
    "print(clf.predict_proba(x))\n",
    "print(clf.predict(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(text, verbose=False):\n",
    "    x = cv.transform([text])\n",
    "    lang = clf.predict(x)\n",
    "    probs = clf.predict_proba(x)\n",
    "    if verbose:\n",
    "        print(\"Probability is: \", probs[0][0])\n",
    "        print(\"The language is\", languages[lang[0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability is:  0.9987415039229451\n",
      "The language is french\n"
     ]
    }
   ],
   "source": [
    "predict(\"Eh bien, mon prince\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability is:  1.514648429106703e-12\n",
      "The language is russian\n"
     ]
    }
   ],
   "source": [
    "predict(\"Анна Павловна кашляла несколько дней, у нее был  грипп , как она говорила  (грипп  был тогда новое слово, употреблявшееся только редкими)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability is:  1.0\n",
      "The language is french\n"
     ]
    }
   ],
   "source": [
    "predict(\"В записочках, разосланных утром с красным лакеем, было написано без различия во всех:   «Si vous n’avez rien de mieux à faire, M. le comte (или mon prince), et si la perspective de passer la soirée chez une pauvre malade ne vous effraye pas trop, je serai charmée de vous voir chez moi entre 7 et 10 heures.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability is:  0.999999999733447\n",
      "The language is french\n"
     ]
    }
   ],
   "source": [
    "predict(\"Je vois que je vous fais peur,  садитесь и рассказывайте.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability is:  6.069362600857917e-06\n",
      "The language is russian\n"
     ]
    }
   ],
   "source": [
    "predict(\"— Вы весь вечер у меня, надеюсь?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probability is:  0.9999999999982663\n",
      "The language is french\n"
     ]
    }
   ],
   "source": [
    "predict(\"— Le général Koutouzoff, — сказал Болконский, ударяя на последнем слоге  zoff , как француз, — a bien voulu de moi pour aide-de-camp...   — Et Lise, votre femme?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy_langdetect.spacy_langdetect.LanguageDetector at 0x104b734d0>"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy_langdetect import LanguageDetector\n",
    "from spacy.language import Language\n",
    "\n",
    "def create_lang_detector(nlp, name):\n",
    "    return LanguageDetector()\n",
    "\n",
    "Language.factory(\"language_detector\", func=create_lang_detector)\n",
    "\n",
    "# nlp = spacy.load(\"en_core_web_sm\")\n",
    "nlp = spacy.load(\"fr_core_news_sm\")\n",
    "nlp.add_pipe('language_detector')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 'en', 'score': 0.9999955493241687}\n",
      "This is an english text. {'language': 'en', 'score': 0.9999964420341838}\n"
     ]
    }
   ],
   "source": [
    "text = 'This is an english text.'\n",
    "doc = nlp(text)\n",
    "print(doc._.language)\n",
    "for sent in doc.sents:\n",
    "    print(sent, sent._.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 'es', 'score': 0.9999938889604822}\n"
     ]
    }
   ],
   "source": [
    "text2 = \"Eh bien, mon prince\"\n",
    "doc = nlp(text2)\n",
    "print(doc._.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "text3 = \"Анна Павловна кашляла несколько дней, у нее был  грипп , как она говорила  (грипп  был тогда новое слово, употреблявшееся только редкими)\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 'ru', 'score': 0.9999954284182743}\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(text3)\n",
    "print(doc._.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 'ru', 'score': 0.7142841147198921}\n"
     ]
    }
   ],
   "source": [
    "text4 = \"Je vois que je vous fais peur,  садитесь и рассказывайте.\"\n",
    "doc = nlp(text4)\n",
    "print(doc._.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'language': 'fr', 'score': 0.9999963567385901}\n"
     ]
    }
   ],
   "source": [
    "text5 = \"Je vois que je vous fais peur\"\n",
    "doc = nlp(text5)\n",
    "print(doc._.language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_mnb import CustomMNB\n",
    "mnb = CustomMNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = data[\"Text\"], data[\"lang_code\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(X, y, test_size = 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.fit(Xtrain, Ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ypred = mnb.predict(Xtest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.99       195\n",
      "           1       1.00      0.97      0.98       147\n",
      "\n",
      "    accuracy                           0.99       342\n",
      "   macro avg       0.99      0.98      0.99       342\n",
      "weighted avg       0.99      0.99      0.99       342\n",
      "\n"
     ]
    }
   ],
   "source": [
    "Ypred = np.asarray(Ypred)\n",
    "print(classification_report(Ytest, Ypred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create own CountVectorizor and test it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = [\n",
    "    \"I don't care, go on and tear me apart\",\n",
    "    \"I don't care if you do,\",\n",
    "    \"Cause in a sky, cause in sky full of stars\",\n",
    "    \"I think I see you\",\n",
    "    \"I think I see you\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "sys.path.append('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_count_vectorizer import CustomCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_cv = CustomCV()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "       [1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 2, 0, 1, 0, 0, 2, 1, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_cv.fit_transform(data).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 19)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer()\n",
    "X = cv.fit_transform(data)\n",
    "X.todense().shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0],\n",
       "        [0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1],\n",
       "        [0, 0, 0, 2, 0, 0, 1, 0, 0, 2, 0, 1, 0, 0, 2, 1, 0, 0, 0],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1],\n",
       "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "fr = [\n",
    "    \"Bonjour, je me suis réveillé le matin,\",\n",
    "    \"Brossé mes dents,\",\n",
    "    \"Je suis allé à l'école\",\n",
    "    \"Fini la journée\",\n",
    "    \"J'écoutais de la musique\",\n",
    "     \"rassemblé tous les livres\",\n",
    "     \"Rebonjour\",\n",
    "     \"J'ai fait mon lit\",\n",
    "     \"Ils m'ont écouté\",\n",
    "     \"Je me suis couché tot\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "ru = [\n",
    "    \"Привет. Я проснулся утром,\",\n",
    "    \"Почистил зубы,\",\n",
    "    \"Отправились в школу\",\n",
    "    \"Закончил день\",\n",
    "    \"я слушал музыку\",\n",
    "    \"Собрал все книги\",\n",
    "    \"привет еще раз\",\n",
    "    \"я заправил свою постель\",\n",
    "    \"Они слушали меня\",\n",
    "    \"я рано лег спать\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fr + ru\n",
    "y = [0]*10 + [1]*10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = [\n",
    "    \"Bonjour, je m'appelle Junior\",\n",
    "    \"Привет, меня зовут Джуниор\",\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from custom_mnb import CustomMNB\n",
    "mnb = CustomMNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "SYMBOLS = '''0123456789!()-[]{};:'\"\\,<>./?@#$%^&*_~'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    " def tokenize(sentence):\n",
    "    tokens = \"\"\n",
    "    for char in sentence.lower():\n",
    "        if char not in SYMBOLS:\n",
    "            tokens += char\n",
    "    return tokens.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_words(X, y):\n",
    "    counts = {}\n",
    "    for doc, label in zip(X, y):\n",
    "        for word in tokenize(doc):\n",
    "            # avoid KeyError\n",
    "            if word not in counts:\n",
    "                counts[word] = [0, 0]\n",
    "            counts[word][label] += 1\n",
    "    return counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = count_words(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prior_probas(counts):\n",
    "    words_a, words_b = 0, 0\n",
    "    for word, val in counts.items():\n",
    "        words_a += val[0]\n",
    "        words_b += val[1]\n",
    "    total = words_a + words_b\n",
    "    prior_a = words_a / total\n",
    "    prior_b = words_b / total\n",
    "    return prior_a, prior_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat0_count, cat1_count = words_a, words_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_probabilities(counts):\n",
    "    \"\"\" word, p(w | cat0), p(w | cat1)\"\"\"\n",
    "    k = 0.5\n",
    "    vocab = [word for word, (cat0, cat1) in counts.items()]\n",
    "    return [(word, (cat0 + k) / (cat0_count + 2 * k),(cat1 + k) / (cat1_count + 2 * k))\n",
    "            for word, (cat0, cat1) in counts.items()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('je', 0.11904761904761904, 0.0625),\n",
       " ('me', 0.07142857142857142, 0.0625),\n",
       " ('suis', 0.11904761904761904, 0.0625),\n",
       " ('réveillé', 0.07142857142857142, 0.0625),\n",
       " ('le', 0.07142857142857142, 0.0625),\n",
       " ('matin', 0.07142857142857142, 0.0625),\n",
       " ('brossé', 0.07142857142857142, 0.0625),\n",
       " ('mes', 0.07142857142857142, 0.0625),\n",
       " ('dents', 0.07142857142857142, 0.0625),\n",
       " ('allé', 0.07142857142857142, 0.0625),\n",
       " ('à', 0.07142857142857142, 0.0625),\n",
       " ('lécole', 0.07142857142857142, 0.0625),\n",
       " ('fini', 0.07142857142857142, 0.0625),\n",
       " ('la', 0.07142857142857142, 0.0625),\n",
       " ('journée', 0.07142857142857142, 0.0625),\n",
       " ('я', 0.07142857142857142, 0.0625),\n",
       " ('проснулся', 0.07142857142857142, 0.0625),\n",
       " ('утром', 0.07142857142857142, 0.0625),\n",
       " ('почистил', 0.023809523809523808, 0.1875),\n",
       " ('зубы', 0.023809523809523808, 0.1875),\n",
       " ('отправились', 0.023809523809523808, 0.1875),\n",
       " ('в', 0.023809523809523808, 0.1875),\n",
       " ('школу', 0.023809523809523808, 0.1875),\n",
       " ('закончил', 0.023809523809523808, 0.1875),\n",
       " ('день', 0.023809523809523808, 0.1875)]"
      ]
     },
     "execution_count": 245,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_probabilities(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_probas(counts):\n",
    "    word_probas = []\n",
    "    k = 0.5\n",
    "    for word, val in counts.items():\n",
    "        pw_a = (val[0] + k) / (words_a + 2*k)\n",
    "        pw_b = (val[1] + k) / (words_b + 2*k)\n",
    "        word_probas.append((word, pw_a, pw_b))\n",
    "    return word_probas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_a, words_b = 0, 0\n",
    "for word, val in counts.items():\n",
    "    words_a += val[0]\n",
    "    words_b += val[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../data/tolstoy_full.txt\") as fh:\n",
    "    text = fh.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "tolstoy = text.split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30183"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tolstoy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— Eh bien, mon prince.\n",
      "Probability is:  0.9987415039229451\n",
      "The language is french\n"
     ]
    }
   ],
   "source": [
    "print(tolstoy[0])\n",
    "predict(tolstoy[0], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "— отвечал, нисколько не смутясь такою встречей, вошедший князь, в придворном, шитом мундире, в чулках, башмаках, и звездах, с светлым выражением плоского лица.\n",
      "Probability is:  0.006340336594678441\n",
      "The language is russian\n"
     ]
    }
   ],
   "source": [
    "print(tolstoy[10])\n",
    "predict(tolstoy[10], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wrpc",
   "language": "python",
   "name": "wrpc"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
